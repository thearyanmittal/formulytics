{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probability of podium based on data in form ([lap number, time per lap, pit stops?, grid number], podium?) -> or expected position\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "drivers = pd.read_excel('data/drivers.xlsx').set_index('driverId')\n",
    "lapTimes = pd.read_csv('data/lapTimes.csv')\n",
    "results = pd.read_csv('data/results.csv')\n",
    "races = pd.read_csv('data/races.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one race, then all in 2012-2016, predict on 2017\n",
    "# features [results: grid, lap number (should increase confidence), position, lap time / min lap time for raceId, elapsed time / min for raceId]\n",
    "# label [results: positionOrder]\n",
    "# because of elapsed time, for 2nd lap onwards\n",
    "\n",
    "race_ids = list(range(948, 969)) + list(range(931, 946)) + list(range(900, 919)) + list(range(880, 900)) + list(range(860, 880))\n",
    "X = []\n",
    "X_grid = []\n",
    "y = []\n",
    "y_pos = []\n",
    "\n",
    "for race_id in race_ids:\n",
    "    if race_id == 917:\n",
    "        continue\n",
    "    lapData = lapTimes[lapTimes['raceId'] == race_id].sort_values(['driverId', 'lap']) #FOR LOOP FOR ALL RACES CONSIDERED\n",
    "    lapData['elapsed'] = np.zeros(len(lapData))\n",
    "    for i in range(len(lapData) - 1):\n",
    "        if lapData.iloc[i]['lap'] == 1:\n",
    "            lapData.iloc[i, lapData.columns.get_loc('elapsed')] = 0\n",
    "        lapData.iloc[i+1, lapData.columns.get_loc('elapsed')] = \\\n",
    "        lapData.iloc[i, lapData.columns.get_loc('elapsed')] + lapData.iloc[i, lapData.columns.get_loc('milliseconds')] / 1000\n",
    "        lap_mins = [None]\n",
    "\n",
    "    for g in (lap_groups := lapData[lapData['raceId'] == race_id].groupby('lap')).groups:\n",
    "        lap_mins.append(lap_groups.get_group(g)['milliseconds'].min())\n",
    "\n",
    "    elapsed_mins = [None]\n",
    "    for g in lap_groups.groups:\n",
    "        elapsed_mins.append(lap_groups.get_group(g)['elapsed'].min())\n",
    "\n",
    "    for (index, row) in lapData[lapData['raceId'] == race_id].sort_values('lap').iterrows():\n",
    "        if (row['lap'] >= 2):\n",
    "            X.append([\n",
    "                row['lap'] / lapData[lapData['raceId'] == race_id]['lap'].max(),\n",
    "                row['position'],\n",
    "                row['milliseconds'] / lap_mins[row['lap']],\n",
    "                row['elapsed'] / elapsed_mins[row['lap']]\n",
    "            ])\n",
    "            X_grid.append(int(results[(results['raceId'] == race_id) & (results['driverId'] == row['driverId'])]['grid']))\n",
    "            y.append(int(results[(results['raceId'] == race_id) & (results['driverId'] == row['driverId'])]['positionOrder']) in (1,2,3))\n",
    "            y_pos.append(int(results[(results['raceId'] == race_id) & (results['driverId'] == row['driverId'])]['positionOrder']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Pos 1: 0.438\n",
      "Grid Pos 2: 0.378\n",
      "Grid Pos 3: 0.321\n",
      "Grid Pos 4: 0.269\n",
      "Grid Pos 5: 0.223\n",
      "Grid Pos 6: 0.183\n",
      "Grid Pos 7: 0.149\n",
      "Grid Pos 8: 0.12\n",
      "Grid Pos 9: 0.096\n",
      "Grid Pos 10: 0.076\n",
      "Grid Pos 11: 0.06\n",
      "Grid Pos 12: 0.048\n",
      "Grid Pos 13: 0.038\n",
      "Grid Pos 14: 0.03\n",
      "Grid Pos 15: 0.023\n",
      "Grid Pos 16: 0.018\n",
      "Grid Pos 17: 0.014\n",
      "Grid Pos 18: 0.011\n",
      "Grid Pos 19: 0.009\n",
      "Grid Pos 20: 0.007\n"
     ]
    }
   ],
   "source": [
    "# logistic regression classifier to predict chance of winning for each initial grid position (cannot take % since uneven data)\n",
    "clf_grid = LogisticRegression(fit_intercept=False).fit([[x] for x in X_grid], y)\n",
    "\n",
    "for i in range(1,21):\n",
    "    print(f'Grid Pos {i}: {round(clf_grid.predict_proba([[i]])[0][1], 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit SGDClassifier to predict final position\n",
    "reg = make_pipeline(StandardScaler(), SGDClassifier(loss='hinge', penalty='l2', max_iter=1000))\n",
    "reg.fit(X, y_pos)\n",
    "reg.predict([[.9, 2, 1.04, 1.04]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "formulytics-WdcqklGX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "436f9d542fa44641a537e533deae025e5db737f99b41c8a356da7ef66e9ea3e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
