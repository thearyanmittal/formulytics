{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probability of podium based on data in form ([lap number, time per lap, pit stops?, grid number], podium?) -> or expected position\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "drivers = pd.read_excel('data/drivers.xlsx').set_index('driverId')\n",
    "lapTimes = pd.read_csv('data/lapTimes.csv')\n",
    "results = pd.read_csv('data/results.csv')\n",
    "races = pd.read_csv('data/races.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add elapsed column\n",
    "lapTimes = lapTimes[lapTimes['raceId'] == 948].sort_values(['driverId', 'lap']) #FOR LOOP FOR ALL RACES CONSIDERED\n",
    "lapTimes['elapsed'] = np.zeros(len(lapTimes))\n",
    "for i in range(len(lapTimes) - 1):\n",
    "    if lapTimes.iloc[i]['lap'] == 1:\n",
    "        lapTimes.iloc[i, lapTimes.columns.get_loc('elapsed')] = 0\n",
    "    lapTimes.iloc[i+1, lapTimes.columns.get_loc('elapsed')] = \\\n",
    "    lapTimes.iloc[i, lapTimes.columns.get_loc('elapsed')] + lapTimes.iloc[i, lapTimes.columns.get_loc('milliseconds')] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features [results: grid, lap number (should increase confidence), position, lap time / min lap time for raceId, elapsed time / min for raceId]\n",
    "# label [results: positionOrder]\n",
    "# because of elapsed time, for 2nd lap onwards\n",
    "\n",
    "# for one race, then all in 2012-2016, predict on 2017\n",
    "race_ids = list(range(948, 969)) + list(range(931, 946))\n",
    "race_id = 948\n",
    "X = []\n",
    "grid_x = []\n",
    "y = []\n",
    "\n",
    "lap_mins = [None]\n",
    "for g in (lap_groups := lapTimes[lapTimes['raceId'] == 948].groupby('lap')).groups:\n",
    "    lap_mins.append(lap_groups.get_group(g)['milliseconds'].min())\n",
    "\n",
    "elapsed_mins = [None]\n",
    "for g in lap_groups.groups:\n",
    "    elapsed_mins.append(lap_groups.get_group(g)['elapsed'].min())\n",
    "\n",
    "for (index, row) in lapTimes[lapTimes['raceId'] == 948].sort_values('lap').iterrows():\n",
    "    if (row['lap'] >= 2):\n",
    "        X.append([\n",
    "            row['lap'] / lapTimes[lapTimes['raceId'] == 948]['lap'].max(),\n",
    "            row['position'],\n",
    "            row['milliseconds'] / lap_mins[row['lap']],\n",
    "            row['elapsed'] / elapsed_mins[row['lap']]\n",
    "        ])\n",
    "        # grid_x.append(int(results[(results['raceId'] == 948) & (results['driverId'] == row['driverId'])]['grid']))\n",
    "        y.append(int(results[(results['raceId'] == 948) & (results['driverId'] == row['driverId'])]['positionOrder']) in (1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0034586  -0.82293703 -0.03063241  0.41689328]] 2.4113648457584143\n"
     ]
    }
   ],
   "source": [
    "# fit logistic regression model\n",
    "clf = LogisticRegression(fit_intercept=True).fit(X, y)\n",
    "# add a random normal distributed variable scaled up by lap constant to probability (return conf not prob?)\n",
    "print(clf.coef_, clf.intercept_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24040017, 0.75959983]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([[.1, 2, 1.03, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf = LogisticRegression().fit(np.array(grid_x).reshape(-1,1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53636589, 0.46363411]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.predict_proba([[1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "formulytics-WdcqklGX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "436f9d542fa44641a537e533deae025e5db737f99b41c8a356da7ef66e9ea3e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
